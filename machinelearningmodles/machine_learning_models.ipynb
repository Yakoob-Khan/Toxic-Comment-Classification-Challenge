{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df=pd.read_csv('../data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>lowered_comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D aww He matches this background colour I m se...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he matches this background colour i am s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man I m really not trying to edit war It j...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i am really not trying to edit war it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>More I can not make any real suggestions on i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can not make any real suggestions on i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>ffe987279560d7ff</td>\n",
       "      <td>And for the second time of asking when your v...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>and for the second time of asking when your v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>ffea4adeee384e90</td>\n",
       "      <td>You should be ashamed of yourself That is a ho...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>you should be ashamed of yourself that is a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>ffee36eab5c267c9</td>\n",
       "      <td>Spitzer Umm theres no actual article for prost...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>spitzer umm theres no actual article for prost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>fff125370e4aaaf3</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>and it looks like it was actually you who put ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>fff46fc426af1f9a</td>\n",
       "      <td>And I really do not think you understand I ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>and i really do not think you understand i ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "0       0000997932d777bf  Explanation Why the edits made under my userna...   \n",
       "1       000103f0d9cfb60f  D aww He matches this background colour I m se...   \n",
       "2       000113f07ec002fd  Hey man I m really not trying to edit war It j...   \n",
       "3       0001b41b1c6bb37e   More I can not make any real suggestions on i...   \n",
       "4       0001d958c54c6e35  You sir are my hero Any chance you remember wh...   \n",
       "...                  ...                                                ...   \n",
       "159566  ffe987279560d7ff   And for the second time of asking when your v...   \n",
       "159567  ffea4adeee384e90  You should be ashamed of yourself That is a ho...   \n",
       "159568  ffee36eab5c267c9  Spitzer Umm theres no actual article for prost...   \n",
       "159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n",
       "159570  fff46fc426af1f9a   And I really do not think you understand I ca...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0           0             0        0       0       0              0   \n",
       "1           0             0        0       0       0              0   \n",
       "2           0             0        0       0       0              0   \n",
       "3           0             0        0       0       0              0   \n",
       "4           0             0        0       0       0              0   \n",
       "...       ...           ...      ...     ...     ...            ...   \n",
       "159566      0             0        0       0       0              0   \n",
       "159567      0             0        0       0       0              0   \n",
       "159568      0             0        0       0       0              0   \n",
       "159569      0             0        0       0       0              0   \n",
       "159570      0             0        0       0       0              0   \n",
       "\n",
       "                                     lowered_comment_text  \n",
       "0       explanation why the edits made under my userna...  \n",
       "1       d aww he matches this background colour i am s...  \n",
       "2       hey man i am really not trying to edit war it ...  \n",
       "3        more i can not make any real suggestions on i...  \n",
       "4       you sir are my hero any chance you remember wh...  \n",
       "...                                                   ...  \n",
       "159566   and for the second time of asking when your v...  \n",
       "159567  you should be ashamed of yourself that is a ho...  \n",
       "159568  spitzer umm theres no actual article for prost...  \n",
       "159569  and it looks like it was actually you who put ...  \n",
       "159570   and i really do not think you understand i ca...  \n",
       "\n",
       "[159571 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Citation : \"https://towardsdatascience.com/multi-label-text-classification-with-scikit-learn-30714b7819c5\"\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "df['lowered_comment_text'] = df['comment_text'].map(lambda text : clean_text(text.lower()))\n",
    "df['comment_text'] = df['comment_text'].map(lambda text : clean_text(text))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "train, test = train_test_split(df,test_size=0.15,random_state = 42)\n",
    "Xtrain = {\"UnLoweredText\": train.comment_text,\"LoweredText\":train.lowered_comment_text}\n",
    "X_test = test.comment_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NBmodelTfdiff': Pipeline(steps=[('tfidf',\n",
      "                 TfidfVectorizer(min_df=5,\n",
      "                                 stop_words={'a', 'about', 'above', 'after',\n",
      "                                             'again', 'against', 'ain', 'all',\n",
      "                                             'am', 'an', 'and', 'any', 'are',\n",
      "                                             'aren', \"aren't\", 'as', 'at', 'be',\n",
      "                                             'because', 'been', 'before',\n",
      "                                             'being', 'below', 'between',\n",
      "                                             'both', 'but', 'by', 'can',\n",
      "                                             'couldn', \"couldn't\", ...},\n",
      "                                 sublinear_tf=True)),\n",
      "                ('clf', OneVsRestClassifier(estimator=MultinomialNB()))]), 'RFmodelTfdiff': Pipeline(steps=[('tfidf',\n",
      "                 TfidfVectorizer(min_df=5,\n",
      "                                 stop_words={'a', 'about', 'above', 'after',\n",
      "                                             'again', 'against', 'ain', 'all',\n",
      "                                             'am', 'an', 'and', 'any', 'are',\n",
      "                                             'aren', \"aren't\", 'as', 'at', 'be',\n",
      "                                             'because', 'been', 'before',\n",
      "                                             'being', 'below', 'between',\n",
      "                                             'both', 'but', 'by', 'can',\n",
      "                                             'couldn', \"couldn't\", ...},\n",
      "                                 sublinear_tf=True)),\n",
      "                ('clf',\n",
      "                 OneVsRestClassifier(estimator=RandomForestClassifier(n_estimators=10,\n",
      "                                                                      random_state=1)))]), 'LRmodelTfdiff': Pipeline(steps=[('tfidf',\n",
      "                 TfidfVectorizer(min_df=5,\n",
      "                                 stop_words={'a', 'about', 'above', 'after',\n",
      "                                             'again', 'against', 'ain', 'all',\n",
      "                                             'am', 'an', 'and', 'any', 'are',\n",
      "                                             'aren', \"aren't\", 'as', 'at', 'be',\n",
      "                                             'because', 'been', 'before',\n",
      "                                             'being', 'below', 'between',\n",
      "                                             'both', 'but', 'by', 'can',\n",
      "                                             'couldn', \"couldn't\", ...},\n",
      "                                 sublinear_tf=True)),\n",
      "                ('clf',\n",
      "                 OneVsRestClassifier(estimator=LogisticRegression(random_state=1)))]), 'NBmodelCountdiff': Pipeline(steps=[('vect', CountVectorizer(min_df=5)),\n",
      "                ('clf', OneVsRestClassifier(estimator=MultinomialNB()))]), 'RFmodelCountdiff': Pipeline(steps=[('vect', CountVectorizer(min_df=5)),\n",
      "                ('clf',\n",
      "                 OneVsRestClassifier(estimator=RandomForestClassifier(n_estimators=10,\n",
      "                                                                      random_state=1)))]), 'LRmodelCountdiff': Pipeline(steps=[('vect', CountVectorizer(min_df=5)),\n",
      "                ('clf',\n",
      "                 OneVsRestClassifier(estimator=LogisticRegression(random_state=1)))])}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Build Pipelines\n",
    "# tdiff - countvect\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Define a pipeline combining a text feature extractor with multi lablel classifier\n",
    "\n",
    "# Create multiple models\n",
    "\n",
    "models = {}\n",
    "\n",
    "def createModels(ngrams):\n",
    "\n",
    "    model = \"NBmodelTfdiff\"\n",
    "\n",
    "    models[model] = Pipeline([\n",
    "                    ('tfidf', TfidfVectorizer(stop_words=stop_words,min_df=5,sublinear_tf=True)),\n",
    "                    ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "                        fit_prior=True, class_prior=None))),\n",
    "                ])\n",
    "\n",
    "    model = \"RFmodelTfdiff\"\n",
    "    models[model] = Pipeline([\n",
    "                    ('tfidf', TfidfVectorizer(stop_words=stop_words,min_df=5,sublinear_tf=True)),\n",
    "                    ('clf', OneVsRestClassifier(RandomForestClassifier(random_state = 1,n_estimators = 10,))),\n",
    "                ])\n",
    "    model = \"LRmodelTfdiff\"\n",
    "    models[model] = Pipeline([\n",
    "                        ('tfidf', TfidfVectorizer(stop_words=stop_words,min_df=5,sublinear_tf=True)),\n",
    "                        ('clf', OneVsRestClassifier(LogisticRegression(random_state = 1))),\n",
    "                    ])\n",
    "    model = \"NBmodelCountdiff\"\n",
    "    models[model] = Pipeline([\n",
    "                    ('vect',CountVectorizer(min_df=5)),\n",
    "                    ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "                        fit_prior=True, class_prior=None)))])\n",
    "    model = \"RFmodelCountdiff\"\n",
    "    models[model] = Pipeline([\n",
    "                    ('vect', CountVectorizer(min_df=5)),\n",
    "                    ('clf', OneVsRestClassifier(RandomForestClassifier(random_state = 1,n_estimators = 10,))),\n",
    "                ])\n",
    "    model = \"LRmodelCountdiff\"\n",
    "    models[model] = Pipeline([\n",
    "                    ('vect', CountVectorizer(min_df=5)),\n",
    "                    ('clf', OneVsRestClassifier(LogisticRegression(random_state = 1))),\n",
    "                ])\n",
    "    return models\n",
    "    \n",
    "\n",
    "ngrams = {\"unigram\":(1,1),\"bigram\":(1,2),\"trigrams\":(1,3)}\n",
    "models = createModels(ngrams)\n",
    "print(models)\n",
    "\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing toxic\n",
      "... Processing severe_toxic\n",
      "... Processing obscene\n",
      "... Processing threat\n",
      "... Processing insult\n",
      "... Processing identity_hate\n",
      "... Processing toxic\n",
      "... Processing severe_toxic\n",
      "... Processing obscene\n",
      "... Processing threat\n",
      "... Processing insult\n",
      "... Processing identity_hate\n",
      "... Processing toxic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louismurerwa/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing severe_toxic\n",
      "... Processing obscene\n",
      "... Processing threat\n",
      "... Processing insult\n",
      "... Processing identity_hate\n",
      "... Processing toxic\n",
      "... Processing severe_toxic\n",
      "... Processing obscene\n",
      "... Processing threat\n",
      "... Processing insult\n",
      "... Processing identity_hate\n",
      "... Processing toxic\n",
      "... Processing severe_toxic\n",
      "... Processing obscene\n",
      "... Processing threat\n",
      "... Processing insult\n",
      "... Processing identity_hate\n",
      "... Processing toxic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louismurerwa/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing severe_toxic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louismurerwa/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing obscene\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louismurerwa/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing threat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louismurerwa/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing insult\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louismurerwa/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing identity_hate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louismurerwa/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing toxic\n",
      "... Processing severe_toxic\n",
      "... Processing obscene\n",
      "... Processing threat\n",
      "... Processing insult\n",
      "... Processing identity_hate\n",
      "... Processing toxic\n",
      "... Processing severe_toxic\n",
      "... Processing obscene\n",
      "... Processing threat\n",
      "... Processing insult\n",
      "... Processing identity_hate\n",
      "... Processing toxic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louismurerwa/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing severe_toxic\n",
      "... Processing obscene\n",
      "... Processing threat\n",
      "... Processing insult\n",
      "... Processing identity_hate\n",
      "... Processing toxic\n",
      "... Processing severe_toxic\n",
      "... Processing obscene\n",
      "... Processing threat\n",
      "... Processing insult\n",
      "... Processing identity_hate\n",
      "... Processing toxic\n",
      "... Processing severe_toxic\n",
      "... Processing obscene\n",
      "... Processing threat\n",
      "... Processing insult\n",
      "... Processing identity_hate\n",
      "... Processing toxic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louismurerwa/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing severe_toxic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louismurerwa/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing obscene\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louismurerwa/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing threat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louismurerwa/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing insult\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louismurerwa/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing identity_hate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louismurerwa/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.974975</td>\n",
       "      <td>NBmodelTfdiffUnLoweredText</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.980051</td>\n",
       "      <td>RFmodelTfdiffUnLoweredText</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.981339</td>\n",
       "      <td>LRmodelTfdiffUnLoweredText</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.967740</td>\n",
       "      <td>NBmodelCountdiffUnLoweredText</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.976284</td>\n",
       "      <td>RFmodelCountdiffUnLoweredText</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.980274</td>\n",
       "      <td>LRmodelCountdiffUnLoweredText</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.974989</td>\n",
       "      <td>NBmodelTfdiffLoweredText</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.979334</td>\n",
       "      <td>RFmodelTfdiffLoweredText</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.981346</td>\n",
       "      <td>LRmodelTfdiffLoweredText</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.967726</td>\n",
       "      <td>NBmodelCountdiffLoweredText</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.976973</td>\n",
       "      <td>RFmodelCountdiffLoweredText</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.980183</td>\n",
       "      <td>LRmodelCountdiffLoweredText</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy                          Model\n",
       "0   0.974975     NBmodelTfdiffUnLoweredText\n",
       "1   0.980051     RFmodelTfdiffUnLoweredText\n",
       "2   0.981339     LRmodelTfdiffUnLoweredText\n",
       "3   0.967740  NBmodelCountdiffUnLoweredText\n",
       "4   0.976284  RFmodelCountdiffUnLoweredText\n",
       "5   0.980274  LRmodelCountdiffUnLoweredText\n",
       "6   0.974989       NBmodelTfdiffLoweredText\n",
       "7   0.979334       RFmodelTfdiffLoweredText\n",
       "8   0.981346       LRmodelTfdiffLoweredText\n",
       "9   0.967726    NBmodelCountdiffLoweredText\n",
       "10  0.976973    RFmodelCountdiffLoweredText\n",
       "11  0.980183    LRmodelCountdiffLoweredText"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame()\n",
    "\n",
    "def trainModel(dataframe):\n",
    "    for trainset in Xtrain:\n",
    "        for model in models:\n",
    "            scores = []\n",
    "            pipeline = models[model]\n",
    "            row = model + trainset\n",
    "            for category in categories:\n",
    "                print('... Processing {}'.format(category))\n",
    "                # train the model using X_dtm & y\n",
    "                pipeline.fit(Xtrain[trainset], train[category])\n",
    "                # compute the testing accuracy\n",
    "                prediction = pipeline.predict(X_test)\n",
    "                accuracy = accuracy_score(test[category], prediction)\n",
    "                scores.append(accuracy)\n",
    "            df2 = {'Model':row,'Accuracy': sum(scores) / len(scores)} \n",
    "            dataframe = dataframe.append(df2, ignore_index = True) \n",
    "            scores = []\n",
    "    return dataframe\n",
    "\n",
    "pred_df = trainModel(pred_df)\n",
    "pred_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy                    0.981346\n",
       "Model       LRmodelTfdiffLoweredText\n",
       "Name: 8, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorteddf = pred_df['Accuracy'].argmax()\n",
    "pred_df.iloc[sorteddf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy                    0.981346\n",
       "Model       LRmodelTfdiffLoweredText\n",
       "Name: 8, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxrow = pred_df['Accuracy'].argmax() \n",
    "pred_df.iloc[maxrow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>Thank you for understanding. I think very high...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>:Dear god this site is horrible.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0002f87b16116a7f</td>\n",
       "      <td>\"::: Somebody will invariably try to add Relig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0003e1cccfd5a40a</td>\n",
       "      <td>\" \\n\\n It says it right there that it IS a typ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00059ace3e3e9a53</td>\n",
       "      <td>\" \\n\\n == Before adding a new product to the l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153150</th>\n",
       "      <td>fff8f64043129fa2</td>\n",
       "      <td>:Jerome, I see you never got around to this…! ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153151</th>\n",
       "      <td>fff9d70fe0722906</td>\n",
       "      <td>==Lucky bastard== \\n http://wikimediafoundatio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153154</th>\n",
       "      <td>fffa8a11c4378854</td>\n",
       "      <td>==shame on you all!!!== \\n\\n You want to speak...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153155</th>\n",
       "      <td>fffac2a094c8e0e2</td>\n",
       "      <td>MEL GIBSON IS A NAZI BITCH WHO MAKES SHITTY MO...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153156</th>\n",
       "      <td>fffb5451268fb5ba</td>\n",
       "      <td>\" \\n\\n == Unicorn lair discovery == \\n\\n Suppo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63978 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "5       0001ea8717f6de06  Thank you for understanding. I think very high...   \n",
       "7       000247e83dcc1211                   :Dear god this site is horrible.   \n",
       "11      0002f87b16116a7f  \"::: Somebody will invariably try to add Relig...   \n",
       "13      0003e1cccfd5a40a  \" \\n\\n It says it right there that it IS a typ...   \n",
       "14      00059ace3e3e9a53  \" \\n\\n == Before adding a new product to the l...   \n",
       "...                  ...                                                ...   \n",
       "153150  fff8f64043129fa2  :Jerome, I see you never got around to this…! ...   \n",
       "153151  fff9d70fe0722906  ==Lucky bastard== \\n http://wikimediafoundatio...   \n",
       "153154  fffa8a11c4378854  ==shame on you all!!!== \\n\\n You want to speak...   \n",
       "153155  fffac2a094c8e0e2  MEL GIBSON IS A NAZI BITCH WHO MAKES SHITTY MO...   \n",
       "153156  fffb5451268fb5ba  \" \\n\\n == Unicorn lair discovery == \\n\\n Suppo...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "5           0             0        0       0       0              0  \n",
       "7           0             0        0       0       0              0  \n",
       "11          0             0        0       0       0              0  \n",
       "13          0             0        0       0       0              0  \n",
       "14          0             0        0       0       0              0  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "153150      0             0        0       0       0              0  \n",
       "153151      0             0        0       0       0              0  \n",
       "153154      0             0        0       0       0              0  \n",
       "153155      1             0        1       0       1              0  \n",
       "153156      0             0        0       0       0              0  \n",
       "\n",
       "[63978 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "testdf = pd.read_csv('../data/test.csv')\n",
    "testlabelsdf = pd.read_csv('../data/test_labels.csv')\n",
    "testdata = pd.merge(testdf, testlabelsdf, on='id', how='outer')\n",
    "\n",
    "testdata.drop(testdata[testdata['toxic'] == -1].index, inplace = True)\n",
    "testdata.drop(testdata[testdata['severe_toxic'] == -1].index, inplace = True)\n",
    "testdata.drop(testdata[testdata['obscene'] == -1].index, inplace = True)\n",
    "testdata.drop(testdata[testdata['threat'] == -1].index, inplace = True)\n",
    "testdata.drop(testdata[testdata['insult'] == -1].index, inplace = True)\n",
    "testdata.drop(testdata[testdata['identity_hate'] == -1].index, inplace = True)\n",
    "testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louismurerwa/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category toxic\n",
      "0.937712963831317\n",
      "Category severe_toxic\n",
      "0.9932476788896183\n",
      "Category obscene\n",
      "0.9670042827221857\n",
      "Category threat\n",
      "0.9966863609365719\n",
      "Category insult\n",
      "0.9642377067116822\n",
      "Category identity_hate\n",
      "0.9901372346744194\n",
      "Accuracy on the whol Test Data:\n",
      "0.9748377046276323\n"
     ]
    }
   ],
   "source": [
    "categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "# train, test = train_test_split(df,test_size=0.15,random_state = 42)\n",
    "\n",
    "\n",
    "pred_df = pd.DataFrame()\n",
    "\n",
    "def predict(model):\n",
    "    modelAccuracy = []\n",
    "    for category in categories:\n",
    "        model.fit(Xtrain['LoweredText'], train[category])\n",
    "        prediction =  model.predict(testdata['comment_text'])\n",
    "        accuracy = accuracy_score(testdata[category], prediction)\n",
    "        modelAccuracy.append(accuracy)\n",
    "        print('Category '+ category)\n",
    "        print(accuracy)\n",
    "    print('Accuracy on the whol Test Data:')\n",
    "    print(sum(modelAccuracy) / len(modelAccuracy))\n",
    "    \n",
    "\n",
    "predict(models['LRmodelTfdiff'])\n",
    "# predict(fittedmodels['LRmodelTfdiffUnLoweredTextUnLoweredText'])\n",
    "# print(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [03:04<00:00, 30.69s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "results = {}\n",
    "\n",
    "def predict(model):\n",
    "    global results\n",
    "    modelAccuracy = []\n",
    "    results[model] = {}\n",
    "    for category in tqdm(categories):\n",
    "        topmodel = models[model]\n",
    "        topmodel.fit(Xtrain['LoweredText'], train[category])\n",
    "        prediction =  topmodel.predict_proba(testdata['comment_text'])\n",
    "        results[model][category] = prediction\n",
    "        #accuracy = accuracy_score(testdata[category], prediction)\n",
    "        #modelAccuracy.append(accuracy)\n",
    "        #print('Category '+ category)\n",
    "        #print(accuracy)\n",
    "    #print('Accuracy on the whol Test Data:')\n",
    "    #print(sum(modelAccuracy) / len(modelAccuracy))\n",
    "predict('RFmodelCountdiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "pkl.dump(results, open('./results_nb.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFmodelCountdiff\n",
      "\ttoxic: 0.9195881807551368\n",
      "\tsevere_toxic: 0.9066093653279254\n",
      "\tobscene: 0.9361160676221201\n",
      "\tthreat: 0.8583203572068543\n",
      "\tinsult: 0.9202934661733997\n",
      "\tidentity_hate: 0.8636906412092052\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "for model_name, model_results in results.items():\n",
    "    print(model_name)\n",
    "    auc_score_lst = []\n",
    "    for category, y_pred_label in model_results.items():\n",
    "        y_pred_label = y_pred_label[:,1]\n",
    "        y_label = testdata[category]\n",
    "        fpr, tpr, _ = roc_curve(y_label, y_pred_label)\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        print('\\t{}: {}'.format(category, auc_score))\n",
    "        auc_score_lst.append(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Citation : \"https://towardsdatascience.com/multi-label-text-classification-with-scikit-learn-30714b7819c5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9007696797157735"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(auc_score_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Helper Functions:\n",
    "# function to clean up excessive spacing and special characters / facial expressions\n",
    "\n",
    "# function to remove accents from text\n",
    "def remove_accents(a):\n",
    "    return unidecode.unidecode(a.decode('utf-8'))\n",
    "\n",
    "# function to remove emojis from text\n",
    "def deEmojify(inputString):\n",
    "    inputString = str(inputString)\n",
    "    return inputString.encode('ascii', 'ignore').decode('ascii')\n",
    "def clean_up(a):\n",
    "    a = a.replace(\"<br />\", \" \")\n",
    "    a = a.replace(\"\\[?\\[.+?\\]?\\]\", \" \")\n",
    "    a = a.replace(\"\\/{3,}\", \" \")\n",
    "    a = a.replace(\"\\&\\#.+\\&\\#\\d+?;\", \" \")\n",
    "    a = a.replace(\"• \", \"\")\n",
    "    a = a.replace(\"\\d+\\&\\#\\d+?;\", \" \")\n",
    "    a = a.replace(\"\\&\\#\\d+?;\", \" \")\n",
    "\n",
    "    # handling facial expressions\n",
    "    a = a.replace(\"\\:\\|\", \"\")\n",
    "    a = a.replace(\"\\:\\)\", \"\")\n",
    "    a = a.replace(\"\\:\\(\", \"\")\n",
    "    a = a.replace(\"\\:\\/\", \"\")\n",
    "\n",
    "    # replacing excessive spacing\n",
    "    a = a.replace(\"\\n\", \" \")\n",
    "    a = a.replace(\"\\s{2,}\", \" \")\n",
    "\n",
    "    return a\n",
    "\n",
    "# function that applies textblob sentiment analysis to a sentence\n",
    "def textblob_sent(sentence):\n",
    "    temp = TextBlob(sentence).sentiment[0]\n",
    "    return round(temp, 3)\n",
    "\n",
    "def cleanTweet(text):\n",
    "    text=' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",text).split())\n",
    "    return text\n",
    "#     Citation:https://stackoverflow.com/questions/8376691/how-to-remove-hashtag-user-link-of-a-tweet-using-regular-expression\n",
    "\n",
    "def compute_sentiment(csvdata):\n",
    "    df = pd.read_csv(csvdata)\n",
    "    df_final = pd.read_csv(csvdata, index_col=0)\n",
    "    df = df[[\"text\"]]\n",
    "    # apply the cleaning methods above\n",
    "    print(\"\\nCleaning up tweet content...\")\n",
    "    df['text'] = df['text'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    df[\"text\"] = clean_up(df[\"text\"])\n",
    "    df['text'] = df[\"text\"].str.lower()\n",
    "    df['text'] = df['text'].replace('\\n', ' ', regex=True)\n",
    "    df['text'] = df['text'].apply(deEmojify)\n",
    "    df['text'] = df['text'].map(lambda text : cleanTweet(text))\n",
    "    return df\n",
    "    print(\"Cleaned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louismurerwa/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3338: DtypeWarning: Columns (0,3,6,7,8,10,15,16,17,22,27,28,29,30,31,36,37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaning up tweet content...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>your president was calling it the china virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i think it is fentanyl from wuhan china that i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i m disgusted too this violence must stop but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the 1 7t taxpayer paided for spending on every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chinx blog ind errr we played defensively and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28405</th>\n",
       "      <td>so at what point are you going to do the right...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28406</th>\n",
       "      <td>in 2011 12 french montana put me on lil durk a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28407</th>\n",
       "      <td>there s a lot of not wuhan between wuhan and uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28408</th>\n",
       "      <td>me hear seh a 18k fi it me rather dead with a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28409</th>\n",
       "      <td>labrador cross coolie puppies to wonderful homes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28410 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0          your president was calling it the china virus\n",
       "1      i think it is fentanyl from wuhan china that i...\n",
       "2      i m disgusted too this violence must stop but ...\n",
       "3      the 1 7t taxpayer paided for spending on every...\n",
       "4      chinx blog ind errr we played defensively and ...\n",
       "...                                                  ...\n",
       "28405  so at what point are you going to do the right...\n",
       "28406  in 2011 12 french montana put me on lil durk a...\n",
       "28407    there s a lot of not wuhan between wuhan and uk\n",
       "28408  me hear seh a 18k fi it me rather dead with a ...\n",
       "28409   labrador cross coolie puppies to wonderful homes\n",
       "\n",
       "[28410 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AntiAsiantweets = compute_sentiment('../Tweet-Scraping/Anti-Asian_tweets.csv')\n",
    "AntiAsiantweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louismurerwa/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def predictTweets(model,df):\n",
    "    modelAccuracy = []\n",
    "    idx = 1\n",
    "    for category in categories:\n",
    "        model.fit(Xtrain['LoweredText'], train[category])\n",
    "        prediction =  model.predict(df['text'])\n",
    "        df.insert(idx, category, prediction, allow_duplicates = True)\n",
    "        idx = idx+1\n",
    "        print(\"Done\")\n",
    "    return df\n",
    "    \n",
    "    \n",
    "\n",
    "AntiAsiantweets = predictTweets(models['LRmodelTfdiff'],AntiAsiantweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "AntiAsiantweets.to_csv('AntiAsianTweetsPredictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
