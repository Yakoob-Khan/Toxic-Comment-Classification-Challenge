{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df=pd.read_csv('../data/train.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "train, test = train_test_split(df,test_size=0.15,random_state = 42)\n",
    "X_train = train.comment_text\n",
    "X_test = test.comment_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Define a pipeline combining a text feature extractor with multi lablel classifier\n",
    "NBmodelTfdiffpipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "                    fit_prior=True, class_prior=None))),\n",
    "            ])\n",
    "\n",
    "RFmodelTfdiffpipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(RandomForestClassifier(random_state = 1,n_estimators = 10))),\n",
    "            ])\n",
    "\n",
    "LRmodelTfdiffpipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(random_state = 1))),\n",
    "            ])\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing toxic\n",
      "... Processing severe_toxic\n",
      "... Processing obscene\n",
      "... Processing threat\n",
      "... Processing insult\n",
      "... Processing identity_hate\n",
      "... Processing toxic\n"
     ]
    }
   ],
   "source": [
    "pred_df = pd.DataFrame() \n",
    "models = {\"NBmodelTfdiff\": NBmodelTfdiffpipeline,\"RFmodelTfdiff\":RFmodelTfdiffpipeline,\"LRmodelTfdiff\":LRmodelTfdiffpipeline }\n",
    "def trainModel(dataframe):\n",
    "    \n",
    "\n",
    "    \n",
    "    for model in models:\n",
    "        scores = []\n",
    "        pipeline = models[model]\n",
    "        for category in categories:\n",
    "            print('... Processing {}'.format(category))\n",
    "            # train the model using X_dtm & y\n",
    "            pipeline.fit(X_train, train[category])\n",
    "            # compute the testing accuracy\n",
    "            prediction = pipeline.predict(X_test)\n",
    "            accuracy = accuracy_score(test[category], prediction)\n",
    "            scores.append(accuracy)\n",
    "        df2 = {'Model':model,'Accuracy': sum(scores) / len(scores)} \n",
    "        dataframe = dataframe.append(df2, ignore_index = True) \n",
    "        scores = []\n",
    "    return dataframe\n",
    "\n",
    "pred_df = trainModel(pred_df)\n",
    "pred_df\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sorteddf = pred_df['Accuracy'].argmax()\n",
    "dataframe.iloc[sorteddf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxrow = pred_df['Accuracy'].argmax() \n",
    "pred_df.iloc[maxrow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "testdf = pd.read_csv('test.csv')\n",
    "testlabelsdf = pd.read_csv('test_labels.csv')\n",
    "testdata = pd.merge(testdf, testlabelsdf, on='id', how='outer')\n",
    "\n",
    "testdata.drop(testdata[testdata['toxic'] == -1].index, inplace = True)\n",
    "testdata.drop(testdata[testdata['severe_toxic'] == -1].index, inplace = True)\n",
    "testdata.drop(testdata[testdata['obscene'] == -1].index, inplace = True)\n",
    "testdata.drop(testdata[testdata['threat'] == -1].index, inplace = True)\n",
    "testdata.drop(testdata[testdata['insult'] == -1].index, inplace = True)\n",
    "testdata.drop(testdata[testdata['identity_hate'] == -1].index, inplace = True)\n",
    "testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.read_csv('../data/test.csv')\n",
    "testlabelsdf = pd.read_csv('../data/test_labels.csv')\n",
    "\n",
    "categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "# train, test = train_test_split(df,test_size=0.15,random_state = 42)\n",
    "\n",
    "models = {\"NBmodelTfdiff\": NBmodelTfdiffpipeline,\"RFmodelTfdiff\":RFmodelTfdiffpipeline,\"LRmodelTfdiff\":LRmodelTfdiffpipeline }\n",
    "pred_df = pd.DataFrame() \n",
    "\n",
    "def predict(model):\n",
    "    modelAccuracy = []\n",
    "    for category in categories:\n",
    "        topmodel = models[model]\n",
    "        topmodel.fit(X_train, train[category])\n",
    "        prediction =  topmodel.predict(testdata['comment_text'])\n",
    "        accuracy = accuracy_score(testdata[category], prediction)\n",
    "        modelAccuracy.append(accuracy)\n",
    "        print('Category '+ category)\n",
    "        print(accuracy)\n",
    "    print('Accuracy on the whol Test Data:' + sum(modelAccuracy) / len(modelAccuracy))\n",
    "predict('LRmodelTfdiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Citation : \"https://towardsdatascience.com/multi-label-text-classification-with-scikit-learn-30714b7819c5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
