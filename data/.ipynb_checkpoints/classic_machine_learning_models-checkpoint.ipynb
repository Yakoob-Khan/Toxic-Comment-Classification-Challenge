{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df=pd.read_csv('train.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "train, test = train_test_split(df,test_size=0.15,random_state = 42)\n",
    "X_train = train.comment_text\n",
    "X_test = test.comment_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Define a pipeline combining a text feature extractor with multi lablel classifier\n",
    "NBmodelTfdiffpipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "                    fit_prior=True, class_prior=None))),\n",
    "            ])\n",
    "\n",
    "RFmodelTfdiffpipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(RandomForestClassifier(random_state = 1,n_estimators = 10))),\n",
    "            ])\n",
    "\n",
    "LRmodelTfdiffpipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(random_state = 1))),\n",
    "            ])\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('tfidf',\n",
      "                 TfidfVectorizer(stop_words={'a', 'about', 'above', 'after',\n",
      "                                             'again', 'against', 'ain', 'all',\n",
      "                                             'am', 'an', 'and', 'any', 'are',\n",
      "                                             'aren', \"aren't\", 'as', 'at', 'be',\n",
      "                                             'because', 'been', 'before',\n",
      "                                             'being', 'below', 'between',\n",
      "                                             'both', 'but', 'by', 'can',\n",
      "                                             'couldn', \"couldn't\", ...})),\n",
      "                ('clf', OneVsRestClassifier(estimator=MultinomialNB()))])\n",
      "... Processing toxic\n",
      "0.9225434491978609\n",
      "... Processing severe_toxic\n",
      "0.9905581550802139\n",
      "... Processing obscene\n",
      "0.9527489973262032\n",
      "... Processing threat\n",
      "0.9978275401069518\n",
      "... Processing insult\n",
      "0.952707219251337\n",
      "... Processing identity_hate\n",
      "0.9904745989304813\n",
      "[0.9225434491978609, 0.9905581550802139, 0.9527489973262032, 0.9978275401069518, 0.952707219251337, 0.9904745989304813]\n",
      "Pipeline(steps=[('tfidf',\n",
      "                 TfidfVectorizer(stop_words={'a', 'about', 'above', 'after',\n",
      "                                             'again', 'against', 'ain', 'all',\n",
      "                                             'am', 'an', 'and', 'any', 'are',\n",
      "                                             'aren', \"aren't\", 'as', 'at', 'be',\n",
      "                                             'because', 'been', 'before',\n",
      "                                             'being', 'below', 'between',\n",
      "                                             'both', 'but', 'by', 'can',\n",
      "                                             'couldn', \"couldn't\", ...})),\n",
      "                ('clf',\n",
      "                 OneVsRestClassifier(estimator=RandomForestClassifier(n_estimators=10,\n",
      "                                                                      random_state=1)))])\n",
      "... Processing toxic\n",
      "0.9499498663101604\n",
      "... Processing severe_toxic\n",
      "0.9903910427807486\n",
      "... Processing obscene\n",
      "0.9734709224598931\n",
      "... Processing threat\n",
      "0.9978693181818182\n",
      "... Processing insult\n",
      "0.9660344251336899\n",
      "... Processing identity_hate\n",
      "0.9914354946524064\n",
      "[0.9499498663101604, 0.9903910427807486, 0.9734709224598931, 0.9978693181818182, 0.9660344251336899, 0.9914354946524064]\n",
      "Pipeline(steps=[('tfidf',\n",
      "                 TfidfVectorizer(stop_words={'a', 'about', 'above', 'after',\n",
      "                                             'again', 'against', 'ain', 'all',\n",
      "                                             'am', 'an', 'and', 'any', 'are',\n",
      "                                             'aren', \"aren't\", 'as', 'at', 'be',\n",
      "                                             'because', 'been', 'before',\n",
      "                                             'being', 'below', 'between',\n",
      "                                             'both', 'but', 'by', 'can',\n",
      "                                             'couldn', \"couldn't\", ...})),\n",
      "                ('clf',\n",
      "                 OneVsRestClassifier(estimator=LogisticRegression(random_state=1)))])\n",
      "... Processing toxic\n",
      "0.9583472593582888\n",
      "... Processing severe_toxic\n",
      "0.9911012700534759\n",
      "... Processing obscene\n",
      "0.9767296122994652\n",
      "... Processing threat\n",
      "0.9978275401069518\n",
      "... Processing insult\n",
      "0.9701704545454546\n",
      "... Processing identity_hate\n",
      "0.9914354946524064\n",
      "[0.9583472593582888, 0.9911012700534759, 0.9767296122994652, 0.9978275401069518, 0.9701704545454546, 0.9914354946524064]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.967810</td>\n",
       "      <td>NBmodelTfdiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.978192</td>\n",
       "      <td>RFmodelTfdiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.980935</td>\n",
       "      <td>LRmodelTfdiff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy          Model\n",
       "0  0.967810  NBmodelTfdiff\n",
       "1  0.978192  RFmodelTfdiff\n",
       "2  0.980935  LRmodelTfdiff"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame() \n",
    "\n",
    "def trainModel(dataframe):\n",
    "    \n",
    "    models = {\"NBmodelTfdiff\": NBmodelTfdiffpipeline,\"RFmodelTfdiff\":RFmodelTfdiffpipeline,\"LRmodelTfdiff\":LRmodelTfdiffpipeline }\n",
    "    \n",
    "    for model in models:\n",
    "        scores = []\n",
    "#         print\n",
    "#         pipeline = models[model]\n",
    "#         print(pipeline)\n",
    "        for category in categories:\n",
    "            print('... Processing {}'.format(category))\n",
    "            # train the model using X_dtm & y\n",
    "            pipeline.fit(X_train, train[category])\n",
    "            # compute the testing accuracy\n",
    "            prediction = pipeline.predict(X_test)\n",
    "            accuracy = accuracy_score(test[category], prediction)\n",
    "            print(accuracy)\n",
    "            scores.append(accuracy)\n",
    "        print(scores)\n",
    "        df2 = {'Model':model,'Accuracy': sum(scores) / len(scores)} \n",
    "\n",
    "        dataframe = dataframe.append(df2, ignore_index = True) \n",
    "        scores = []\n",
    "\n",
    "    return dataframe\n",
    "pred_df = trainModel(pred_df)\n",
    "pred_df\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sorteddf = pred_df['Accuracy'].argmax()\n",
    "dataframe.iloc[sorteddf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy         0.980935\n",
       "Model       LRmodelTfdiff\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxrow = pred_df['Accuracy'].argmax() \n",
    "pred_df.iloc[maxrow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.read_csv('test.csv')\n",
    "testdf = pd.read_csv('test_labels.csv')\n",
    "categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "# train, test = train_test_split(df,test_size=0.15,random_state = 42)\n",
    "\n",
    "pred_df = pd.DataFrame() \n",
    "def predict(model):\n",
    "    for category in categories:\n",
    "        topmodel = models[model]\n",
    "        topmodel.fit(X_train, train[category])\n",
    "        prediction = pipeline.predict(testdf.comment_text)\n",
    "        \n",
    "        accuracy = accuracy_score(test_labels[category], prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Citation : \"https://towardsdatascience.com/multi-label-text-classification-with-scikit-learn-30714b7819c5\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
